{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.869 Final Project\n",
    "\n",
    "By Emily Hu and Janelle Sands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Downloading the dataset\n",
    "\n",
    "The dataset was downloaded and processed from MUSCIMA++ <https://ufal.mff.cuni.cz/muscima>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Root of data. Change this to match your directory structure. \n",
    "# Your submissions should NOT include the data.\n",
    "# You might want to mount your google drive, if you're using google colab. \n",
    "# If you ran the cell above, your google drive will be located at '/content/gdrive/My Drive'\n",
    "# datadir should contain train/ val/ and test/\n",
    "\n",
    "\n",
    "data_dir = \"data_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Training a Model\n",
    "\n",
    "This code was adapted from the Miniplaces 2 PSET, which referenced the following tutorial: <https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\georg\\anaconda3\\envs\\pytorch\\lib\\site-packages (4.38.0)\n",
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n",
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# You might not have tqdm, which gives you nice progress bars\n",
    "!pip install tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize an Empty Model\n",
    "\n",
    "Initialize an empty model, that will input an image, and output a classification. Takes in an architecture name, and outputs a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, resume_from = None):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    # The model (nn.Module) to return\n",
    "    model_ft = None\n",
    "    # The input image is expected to be (input_size, input_size)\n",
    "    input_size = 0\n",
    "    \n",
    "    # You may NOT use pretrained models!! \n",
    "    use_pretrained = False\n",
    "    \n",
    "    # By default, all parameters will be trained (useful when you're starting from scratch)\n",
    "    # Within this function you can set .requires_grad = False for various parameters, if you\n",
    "    # don't want to learn them\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Invalid model name!\")\n",
    "    \n",
    "    if resume_from is not None:\n",
    "        print(\"Loading weights from %s\" % resume_from)\n",
    "        model_ft.load_state_dict(torch.load(resume_from))\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "With input size from the model, load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(input_size, batch_size, shuffle = True):\n",
    "    # How to transform the image when you are loading them.\n",
    "    # you'll likely want to mess with the transforms on the training set.\n",
    "    \n",
    "    # For now, we resize/crop the image to the correct input size for our network,\n",
    "    # then convert it to a [C,H,W] tensor, then normalize it to values with a given mean/stdev. These normalization constants\n",
    "    # are derived from aggregating lots of data and happen to produce better results.\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "    # Create training and validation datasets\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in data_transforms.keys()}\n",
    "    # Create training and validation dataloaders\n",
    "    # Never shuffle the test set\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False if x != 'train' else shuffle, num_workers=4) for x in data_transforms.keys()}\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A helper function that trains the given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, save_dir = None, save_all_epochs=False, num_epochs=25):\n",
    "    '''\n",
    "    model: The NN to train\n",
    "    dataloaders: A dictionary containing at least the keys \n",
    "                 'train','val' that maps to Pytorch data loaders for the dataset\n",
    "    criterion: The Loss function\n",
    "    optimizer: The algorithm to update weights \n",
    "               (Variations on gradient descent)\n",
    "    num_epochs: How many epochs to train for\n",
    "    save_dir: Where to save the best model weights that are found, \n",
    "              as they are found. Will save to save_dir/weights_best.pt\n",
    "              Using None will not write anything to disk\n",
    "    save_all_epochs: Whether to save weights for ALL epochs, not just the best\n",
    "                     validation error epoch. Will save to save_dir/weights_e{#}.pt\n",
    "    '''\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # TQDM has nice progress bars\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # torch.max outputs the maximum value, and its index\n",
    "                    # Since the input is batched, we take the max along axis 1\n",
    "                    # (the meaningful outputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backprop + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer & Loss\n",
    "A loss function, and an optimization function to try to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model):\n",
    "    # Get all the parameters\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "    # Use SGD\n",
    "#     optimizer = optim.SGD(params_to_update, lr=0.0001, momentum=0.9)\n",
    "#     optimizer = optim.ASGD(params_to_update, lr=0.0001)\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
    "    return optimizer\n",
    "\n",
    "def get_loss():\n",
    "    # Create an instance of the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Our data is set up to follow the expected format of the  `ImageFolder <https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder>`__\n",
    "dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "# You can add your own, or modify these however you wish!\n",
    "model_name = \"resnet\"\n",
    "# model_name = \"alexnet\"\n",
    "# model_name = \"densenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 11\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "# You should use a power of 2.\n",
    "batch_size = 16\n",
    "\n",
    "# Shuffle the input data?\n",
    "shuffle_datasets = True\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 8\n",
    "\n",
    "### IO\n",
    "# Path to a model file to use to start weights at\n",
    "resume_from = \"weights/resnet_adam.pt\"\n",
    "# resume_from = None\n",
    "\n",
    "# Directory to save weights to\n",
    "save_dir = \"weights\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save weights for all epochs, not just the best one\n",
    "save_all_epochs = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tying it all together - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from weights/resnet_adam.pt\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(model_name = model_name, num_classes = num_classes, resume_from = resume_from)\n",
    "dataloaders = get_dataloaders(input_size, batch_size, shuffle_datasets)\n",
    "criterion = get_loss()\n",
    "\n",
    "# Move the model to the gpu if needed\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = make_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/7\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593af9493b504c00a41ec960efa76853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cbe2bac7f58a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m trained_model, validation_history = train_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer,\n\u001b[1;32m----> 3\u001b[1;33m            save_dir=save_dir, save_all_epochs=save_all_epochs, num_epochs=num_epochs)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-ebd91182d9ed>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, save_dir, save_all_epochs, num_epochs)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m# TQDM has nice progress bars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model!\n",
    "trained_model, validation_history = train_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer,\n",
    "           save_dir=save_dir, save_all_epochs=save_all_epochs, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"weights/alexnet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Inference\n",
    "\n",
    "Evaluates performance of model (on validation data), and uses it for inference (on the test data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, is_labelled = False, generate_labels = True, k = 5):\n",
    "    # If is_labelled, we want to compute loss, top-1 accuracy and top-5 accuracy\n",
    "    # If generate_labels, we want to output the actual labels\n",
    "    # Set the model to evaluate mode\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_top1_correct = 0\n",
    "    running_top5_correct = 0\n",
    "    predicted_labels = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    # Iterate over data.\n",
    "    # TQDM has nice progress bars\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        tiled_labels = torch.stack([labels.data for i in range(k)], dim=1) \n",
    "        # Makes this to calculate \"top 5 prediction is correct\"\n",
    "        # [[label1 label1 label1 label1 label1], [label2 label2 label2 label label2]]\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Get model outputs and calculate loss\n",
    "            outputs = model(inputs)\n",
    "            if is_labelled:\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # torch.topk outputs the maximum values, and their indices\n",
    "            # Since the input is batched, we take the max along axis 1\n",
    "            # (the meaningful outputs)\n",
    "            _, preds = torch.topk(outputs, k=5, dim=1)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            if generate_labels:\n",
    "                # We want to store these results\n",
    "                nparr = preds.cpu().detach().numpy()\n",
    "                nparr_probs = probs.cpu().detach().numpy()\n",
    "                top_probs = [[nparr_probs[p][top_idx] for top_idx in nparr[p]] for p in range(len(nparr_probs))]\n",
    "                predicted_labels.extend([list(nparr[i]) for i in range(len(nparr))])\n",
    "                predicted_probs.extend([list(top_probs[i]) for i in range(len(top_probs))])\n",
    "\n",
    "        if is_labelled:\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            # Check only the first prediction\n",
    "            running_top1_correct += torch.sum(preds[:, 0] == labels.data)\n",
    "            # Check all 5 predictions\n",
    "            running_top5_correct += torch.sum(preds == tiled_labels)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Only compute loss & accuracy if we have the labels\n",
    "    if is_labelled:\n",
    "        epoch_loss = float(running_loss / len(dataloader.dataset))\n",
    "        epoch_top1_acc = float(running_top1_correct.double() / len(dataloader.dataset))\n",
    "        epoch_top5_acc = float(running_top5_correct.double() / len(dataloader.dataset))\n",
    "    else:\n",
    "        epoch_loss = None\n",
    "        epoch_top1_acc = None\n",
    "        epoch_top5_acc = None\n",
    "    \n",
    "    # Return everything\n",
    "    return epoch_loss, epoch_top1_acc, epoch_top5_acc, predicted_labels, predicted_probs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52374803ff547db8ca41c3985d56df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get data on the validation set\n",
    "# Setting this to false will be a little bit faster\n",
    "generate_validation_labels = False\n",
    "val_loss, val_top1, val_top5, val_labels, _ = evaluate(model, dataloaders['val'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 5)\n",
    "print(\"Validation: \", val_top1)\n",
    "\n",
    "# Get predictions for the training set\n",
    "# train_loss, train_top1, train_top5, train_labels, _ = evaluate(model, dataloaders['train'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 5)\n",
    "# print(\"Train: \", train_top1)\n",
    "\n",
    "\n",
    "# Get predictions for the test set\n",
    "shuffle_datasets = False\n",
    "dataloaders = get_dataloaders(input_size, batch_size, shuffle_datasets)\n",
    "_, _, _, test_labels, test_probs = evaluate(model, dataloaders['test'], criterion, is_labelled = False, generate_labels = True, k = 5)\n",
    "# print(test_labels, test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-Readable Inference\n",
    "\n",
    "Convert the predictions into a JSON with top 5 predictions for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions to:\n",
      "C:\\Users\\georg\\Desktop\\MIT\\Fall 19\\6819\\project\\test_set_predictions14.json\n"
     ]
    }
   ],
   "source": [
    "''' These convert your dataset labels into nice human readable names '''\n",
    "\n",
    "import json\n",
    "\n",
    "def label_number_to_name(lbl_ix, pred):\n",
    "    return dataloaders['val'].dataset.classes[lbl_ix] + \" {0:.4f}\".format(pred)\n",
    "\n",
    "def dataset_labels_to_names(dataset_labels, dataset_probs, dataset_name):\n",
    "    # dataset_name is one of 'train','test','val'\n",
    "    dataset_root = os.path.join(data_dir, dataset_name)\n",
    "    found_files = []\n",
    "    for parentdir, subdirs, subfns in os.walk(dataset_root):\n",
    "        parentdir_nice = os.path.relpath(parentdir, dataset_root)\n",
    "        found_files.extend([os.path.join(parentdir_nice, fn) for fn in subfns if fn.endswith('.jpg')])\n",
    "    # Sort alphabetically, this is the order that our dataset will be in\n",
    "    found_files.sort()\n",
    "    # Now we have two parallel arrays, one with names, and the other with predictions\n",
    "    assert len(found_files) == len(dataset_labels), \"Found more files than we have labels\"\n",
    "    preds = {os.path.basename(found_files[i]):list(map(label_number_to_name, dataset_labels[i], dataset_probs[i])) for i in range(len(found_files))}\n",
    "#     out = list(zip(preds, dataset_probs))\n",
    "    return preds\n",
    "    \n",
    "\n",
    "test_labels_js = dataset_labels_to_names(test_labels, test_probs, \"test\")\n",
    "\n",
    "output_test_labels = \"test_set_predictions\"\n",
    "output_salt_number = 0\n",
    "\n",
    "output_label_dir = \".\"\n",
    "\n",
    "while os.path.exists(os.path.join(output_label_dir, '%s%d.json' % (output_test_labels, output_salt_number))):\n",
    "    output_salt_number += 1\n",
    "    # Find a filename that doesn't exist\n",
    "    \n",
    "\n",
    "with open(os.path.join(output_label_dir, '%s%d.json' % (output_test_labels, output_salt_number)), \"w\") as f:\n",
    "    json.dump(test_labels_js, f, sort_keys=True, indent=4)\n",
    "    \n",
    "print(\"Wrote predictions to:\\n%s\" % os.path.abspath(os.path.join(output_label_dir, '%s%d.json' % (output_test_labels, output_salt_number))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
